{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt) : \n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = [{\"role\" : \"user\", \"content\" : prompt},],\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 저는 인공지능 챗봇입니다. 무엇을 도와드릴까요?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_response(\"안녕! 넌 누구야?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI \n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "client_llama = OpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [ChatMessage(role=\"user\", content=\"안녕! 넌 누구야?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(message=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, content='안녕하세요! 저는 인공지능 챗봇입니다. 무엇을 도와드릴까요?', additional_kwargs={}), raw={'id': 'chatcmpl-9BMuqP3gDh2xWuZgLf1Kwy5vVDroI', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='안녕하세요! 저는 인공지능 챗봇입니다. 무엇을 도와드릴까요?', role='assistant', function_call=None, tool_calls=None))], 'created': 1712496724, 'model': 'gpt-3.5-turbo-0125', 'object': 'chat.completion', 'system_fingerprint': 'fp_b28b39ffa8', 'usage': CompletionUsage(completion_tokens=36, prompt_tokens=20, total_tokens=56)}, delta=None, logprobs=None, additional_kwargs={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client_llama.chat(message)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요! 저는 인공지능 챗봇입니다. 무엇을 도와드릴까요?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI의 sora 모델은 지난 2021년 발표된 언어 모델로, 대규모 파라미터를 가진 최신 자연어 처리 모델 중 하나입니다. 이 모델은 GPT-3 모델과 유사한 구조를 갖추고 있으며, 다양한 자연어 처리 작업을 수행할 수 있습니다.\n",
      "\n",
      "sora 모델은 대용량의 데이터를 사용하여 사전 훈련되었고, 다양한 언어 이해 및 생성 작업에 잘 작동합니다. 이 모델을 사용하면 자연어 처리 작업을 보다 쉽게 수행할 수 있으며, 웹 검색, 기계 번역, 질문 응답, 요약 등 다양한 작업에 활용할 수 있습니다.\n",
      "\n",
      "또한, sora 모델은 대용량의 텍스트 데이터를 기반으로 학습되어 있기 때문에, 다양한 언어 및 분야에 대한 지식을 갖추고 있어 다양한 자연어 처리 작업에 유용하게 활용될 수 있습니다. 해당 모델은 연구 및 상업적인 용도로도 활용이 가능하며, 자연어 처리 분야에서의 혁신적인 발전을 이끌어낼 수 있는 기술 중 하나로 평가되고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# outdated knowledge\n",
    "\n",
    "query = \"OpenAI의 sora 모델에 대해서 설명해줘\"\n",
    "\n",
    "resp = get_response(query)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Utilizing the given context, please answer the question.\n",
    "\n",
    "[context]\n",
    "Sora is a text-to-video model that can generate videos based on short descriptive prompts[195] as well as extend existing videos forwards or backwards in time.[196] It can generate videos with resolution up to 1920x1080 or 1080x1920. The maximal length of generated videos is unknown.\n",
    "\n",
    "Sora's development team named it after the Japanese word for \"sky\", to signify its \"limitless creative potential\".[195] Sora's technology is an adaptation of the technology behind the DALL·E 3 text-to-image model.[197] OpenAI trained the system using publicly-available videos as well as copyrighted videos licensed for that purpose, but did not reveal the number or the exact sources of the videos.[195]\n",
    "\n",
    "OpenAI demonstrated some Sora-created high-definition videos to the public on February 15, 2024, stating that it could generate videos up to one minute long. It also shared a technical report highlighting the methods used to train the model, and the model's capabilities.[197] It acknowledged some of its shortcomings, including struggles simulating complex physics.[198] Will Douglas Heaven of the MIT Technology Review called the demonstration videos \"impressive\", but noted that they must have been cherry-picked and might not represent Sora's typical output.[197]\n",
    "\n",
    "Despite skepticism from some academic leaders following Sora's public demo, notable entertainment-industry figures have shown significant interest in the technology's potential. In an interview, actor/filmmaker Tyler Perry expressed his astonishment at the technology's ability to generate realistic video from text descriptions, citing its potential to revolutionize storytelling and content creation. He said that his excitement about Sora's possibilities was so strong that he had decided to pause plans for expanding his Atlanta-based movie studio.[199]\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
